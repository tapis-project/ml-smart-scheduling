{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fa0f555-f256-4a0f-b5f2-dd85754c7e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Exploration with skx_normal queue data for stampede2 Feb 1, 2022 - August 1, 2022 (not including Aug 1,2022)\n",
    "import sys\n",
    "sys.path.append('/home/jovyan/work/')\n",
    "sys.path.append('/home/jovyan/work/src')\n",
    "sys.path.append('/home/jovyan/work/src/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c16744fb-3a08-4328-bbb1-d3120d558531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import create_input_data\n",
    "df_feb = create_input_data.read_data(csv_file_name=\"../data/raw/skx_anon_jobs_1Feb2022_1Aug2022_normal_sorted.csv\", parse_dates_col=[4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80efdeaf-cd47-4ff3-90be-3cb9b783d83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 199744 entries, 0 to 199743\n",
      "Data columns (total 17 columns):\n",
      " #   Column            Non-Null Count   Dtype         \n",
      "---  ------            --------------   -----         \n",
      " 0   jobid             199744 non-null  int64         \n",
      " 1   user              199744 non-null  object        \n",
      " 2   account           199744 non-null  object        \n",
      " 3   state             199744 non-null  object        \n",
      " 4   submit            199744 non-null  datetime64[ns]\n",
      " 5   start             199744 non-null  datetime64[ns]\n",
      " 6   end               199744 non-null  datetime64[ns]\n",
      " 7   reqcpus           199744 non-null  int64         \n",
      " 8   nnodes            199744 non-null  int64         \n",
      " 9   max_minutes       199744 non-null  int64         \n",
      " 10  queue_minutes     199744 non-null  int64         \n",
      " 11  backlog_minutes   199744 non-null  int64         \n",
      " 12  backlog_num_jobs  199744 non-null  int64         \n",
      " 13  running_num_jobs  199744 non-null  int64         \n",
      " 14  running_minutes   199744 non-null  int64         \n",
      " 15  run_minutes       199744 non-null  int64         \n",
      " 16  nodelist          199744 non-null  object        \n",
      "dtypes: datetime64[ns](3), int64(10), object(4)\n",
      "memory usage: 25.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_feb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06b7cbcf-d913-4e00-ac37-c7f20ae07a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial total number of jobs:  199744\n",
      "Jobs with 0 queue minutes:  57935\n",
      "Jobs with queue minutes leq 5:  89998\n",
      "Jobs with queue minutes:  57935\n",
      "Percentage of jobs with 0 queue minutes:  0.2900462592117911\n",
      "After dropping zero minute jobs, shortest queue time is:  1\n",
      "Jobs with 0 queue minutes:  57935\n",
      "HIGH number of days threshold:  2  ( 2880  minutes)\n",
      "Jobs with HIGH queue minutes:  5831\n",
      "Percentage of jobs with HIGH queue minutes:  0.029192366228772828\n",
      "Final total number of jobs:  135978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "queue_minutes_bin\n",
       "0    75668\n",
       "4    34888\n",
       "1    13259\n",
       "2     7206\n",
       "3     4957\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "# df = df_jan\n",
    "df = df_feb\n",
    "\n",
    "# How many jobs sat in queue for 0 minutes?\n",
    "nbr_jobs = len(df)\n",
    "nbr_zero_queue_min_jobs = len(df[df.queue_minutes == 0])\n",
    "small_minutes_threshhold = 5\n",
    "nbr_small_queue_min_jobs = len(df[df.queue_minutes <= small_minutes_threshhold])\n",
    "print(\"Initial total number of jobs: \", nbr_jobs)\n",
    "print(\"Jobs with 0 queue minutes: \", nbr_zero_queue_min_jobs)\n",
    "print(f\"Jobs with queue minutes leq {small_minutes_threshhold}: \", nbr_small_queue_min_jobs)\n",
    "print(\"Jobs with queue minutes: \", nbr_zero_queue_min_jobs)\n",
    "print(\"Percentage of jobs with 0 queue minutes: \", float(nbr_zero_queue_min_jobs)/nbr_jobs)\n",
    "\n",
    "# Optionally, drop the rows (jobs) that sat in queue for 0 minutes \n",
    "DROP_ZERO_QUEUE_MINUTES = True\n",
    "if DROP_ZERO_QUEUE_MINUTES:\n",
    "    df = df.drop(df[df.queue_minutes == 0].index)\n",
    "    min_queue_minutes = df['queue_minutes'].min()\n",
    "    print(\"After dropping zero minute jobs, shortest queue time is: \", min_queue_minutes)\n",
    "\n",
    "print(\"Jobs with 0 queue minutes: \", nbr_zero_queue_min_jobs)# How many jobs sat in queue for > more than x days?\n",
    "NBR_DAYS_HIGH = 2\n",
    "nbr_minutes_high = NBR_DAYS_HIGH * 24 * 60 \n",
    "nbr_high_queue_min_jobs = len(df[df.queue_minutes >= nbr_minutes_high])\n",
    "print(\"HIGH number of days threshold: \", NBR_DAYS_HIGH, \" (\", nbr_minutes_high, \" minutes)\")\n",
    "print(\"Jobs with HIGH queue minutes: \", nbr_high_queue_min_jobs)\n",
    "print(\"Percentage of jobs with HIGH queue minutes: \", float(nbr_high_queue_min_jobs)/nbr_jobs)\n",
    "\n",
    "# Optionally, drop the rows (jobs) that sat in queue for 0 minutes \n",
    "DROP_HIGH_QUEUE_MINUTES = True\n",
    "if DROP_HIGH_QUEUE_MINUTES:\n",
    "    df = df.drop(df[df.queue_minutes >= nbr_minutes_high].index)\n",
    "\n",
    "print(\"Final total number of jobs: \", len(df))\n",
    "\n",
    "# Add a new column, queue_minutes_bin, which is the bin of the \n",
    "bin_threshhold = 10\n",
    "bin_size_factor = 6 # implies bins of size 60 min\n",
    "bin_size = bin_threshhold * bin_size_factor\n",
    "nbr_bins = 5\n",
    "\n",
    "df['queue_minutes_bin'] = df['queue_minutes'] / bin_size\n",
    "df = df.astype({'queue_minutes_bin': 'int'})\n",
    "df['queue_minutes_bin'].unique()\n",
    "# for jobs in a bin number larger than the number of bins -1 (bins are 0-indexed), just \n",
    "# put them in the largest bin. \n",
    "df['queue_minutes_bin'] = np.where(df['queue_minutes_bin'] > (nbr_bins - 1), (nbr_bins - 1), df['queue_minutes_bin'])\n",
    "# print the final bin counts\n",
    "df['queue_minutes_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4512d6bb-60e4-444f-bc84-0513e0f60743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "def split_df_current_future(df, cutoff_fraction=0.75, cutoff_datetime=None):\n",
    "    \"\"\"\n",
    "    Split a jobs dataframe into a current and future set. \n",
    "      * cutoff_fraction (float): the fraction to use for current.\n",
    "      * cutoff_datetime, if supplied, should be the date_time to use as the cutoff point.\n",
    "        When supplied, cutoff_fraction is ignored.\n",
    " \n",
    "    Returns two dataframes, current and future\n",
    "    \"\"\"\n",
    "    # if cutoff_datetime is provided, just use that \n",
    "    if cutoff_datetime: \n",
    "        current = df[df['submit'] <= cutoff_datetime]\n",
    "        future = df[df['submit'] > cutoff_datetime]\n",
    "        return current, future \n",
    "    # otherwise, we are using cutoff_fraction. \n",
    "    if not 0 < cutoff_fraction < 1:\n",
    "        print(\"Invalid cutoff_fraction; values should be between 0 and 1.\")\n",
    "        return None, None \n",
    "    # the following uses np.quantile to split the df on the submit column using the cutoff_fraction\n",
    "    current = df[df['submit']<=np.quantile(df['submit'], cutoff_fraction )]\n",
    "    future = df[df['submit']>np.quantile(df['submit'], cutoff_fraction )]\n",
    "    return current, future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92f144a8-4261-45af-a690-fd69554bdd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  117359  Future:  18619\n",
      "Max current:  2022-06-30 23:42:18  Min future:  2022-07-01 00:42:53\n"
     ]
    }
   ],
   "source": [
    "current, future = split_df_current_future(df, cutoff_fraction=0.75, cutoff_datetime=\"2022-07-01\")\n",
    "print(\"Current: \", len(current), \" Future: \", len(future))\n",
    "print(\"Max current: \", current[\"submit\"].max(), \" Min future: \", future['submit'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d858782-0179-44d7-9ea1-1a0676e74445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the columns of the independent and dependent vars, repsectively:\n",
    "X_cols = ['nnodes', \n",
    "          'max_minutes', \n",
    "          'backlog_minutes', \n",
    "          'backlog_num_jobs', \n",
    "          'running_num_jobs', \n",
    "          'running_minutes',\n",
    "         ]\n",
    "y_col = 'queue_minutes_bin'\n",
    "\n",
    "# whether to train on the full dataset (after splitting) or to use the \"current\"\n",
    "TRAIN_ON_FULL = True \n",
    "\n",
    "# Train-test split --------\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Create independent and dependent vars\n",
    "X = df[X_cols]\n",
    "X_current = current[X_cols]\n",
    "X_future = future[X_cols]\n",
    "y = df[y_col]\n",
    "y_current = current[y_col]\n",
    "y_future = future[y_col]\n",
    "\n",
    "if TRAIN_ON_FULL:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=1)\n",
    "else:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_current, y_current, test_size=0.2, stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8233569c-fa35-45a5-9721-7c969332a75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on TEST\n",
      "*******************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.97      0.81     15134\n",
      "           1       0.00      0.00      0.00      2652\n",
      "           2       0.00      0.00      0.00      1441\n",
      "           3       0.00      0.00      0.00       991\n",
      "           4       0.81      0.72      0.76      6978\n",
      "\n",
      "    accuracy                           0.72     27196\n",
      "   macro avg       0.30      0.34      0.31     27196\n",
      "weighted avg       0.60      0.72      0.65     27196\n",
      "\n",
      "Performance on TRAIN\n",
      "********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.97      0.81     60534\n",
      "           1       0.00      0.00      0.00     10607\n",
      "           2       0.00      0.00      0.00      5765\n",
      "           3       0.00      0.00      0.00      3966\n",
      "           4       0.81      0.72      0.76     27910\n",
      "\n",
      "    accuracy                           0.72    108782\n",
      "   macro avg       0.30      0.34      0.31    108782\n",
      "weighted avg       0.60      0.72      0.65    108782\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "lr = LogisticRegression(random_state=1, max_iter=1000)\n",
    "p = pipeline = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('lr', lr),\n",
    "])\n",
    "\n",
    "# fit the pipeline \n",
    "p.fit(X_train, y_train)\n",
    "model = p \n",
    "# or, fit the LG model by hand with no standardization \n",
    "# model = lr.fit(X_train, y_train)\n",
    "\n",
    "# print the report\n",
    "print(f\"Performance on TEST\\n*******************\\n{classification_report(y_test, model.predict(X_test))}\")\n",
    "print(f\"Performance on TRAIN\\n********************\\n{classification_report(y_train, model.predict(X_train))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cc170d-044e-46be-971e-d561674a111b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
